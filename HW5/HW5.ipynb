{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bW5BipraiQiE"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzk_94Ey_KZz"
      },
      "source": [
        "#HW5: Autoencoders\n",
        "\n",
        "In this homework, we will explore how to develop a simple Autoencoder. As a dataset, we will use the MNIST dataset. It contains handwritten digits images.\n",
        "In the first part, we will learn how to develop a simple shallow autoencoder, then we will develop a deep version. Next, we will experiment with the application of autoencoder on denoising data task (denoising-autoencoder). Finally, we will apply this model to sequential domains, considering the IMDB dataset, already used in HW4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SUqAWqAXRr1"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJA-D-6h3D6b"
      },
      "source": [
        "###Load Dataset\n",
        "We load the MNIST dataset, using tf.keras.datasets. The dataset contains 60,000 training images and 10,000 testing images.\n",
        "The value of each pixel is between 0 and 255, and it represents a point of an image of size 28 x 28. We will normalize all values between 0 and 1, and we will flatten the 28x28 images into vectors of size 784.\n",
        "Finally, since no validation set is defined, we split the test set in a validation set and a new test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmt1Au8CX-ra"
      },
      "source": [
        "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "x_valid = x_train[:10000]\n",
        "x_train = x_train[10000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6KiNMUN9_ke"
      },
      "source": [
        "##[TO COMPLETE] Exercise 5.1: Singular Value Decomposition\n",
        "\n",
        "Principal component analysis (PCA) and singular value decomposition (SVD) are both classical linear dimensionality reduction methods that attempt to find linear combinations of features in the original high dimensional data matrix to construct a meaningful representation of the dataset.\n",
        "In this first part of the HW, we will focus our attention on SVD decomposition, a numerical stable method. Given a matrix X, the SVD decomposes it into the product of two unitary matrices V and U and a rectangular diagonal matrix of singular values S:\n",
        "\n",
        "$$ X=V \\cdot S \\cdot U^T.$$\n",
        "\n",
        "SVD is already implemented in NumPy as np.linalg.svd. In our case, the X matrix will represent the training set, where each row is a sample (therefore the number of columns will be the number of input features).\n",
        "\n",
        "Note that, the X matrix in our case will have a huge number of rows (we have 50000 input samples) and only 784 columns. Therefore to optime the memory consumption, we can compute the SVD of the covariance matrix. An interesting property of the SVD is that we compute the decomposition of the covariance matrix $C= X^T \\cdot X$, and we will obtain the following decomposition:\n",
        "\n",
        "$$ C= U \\cdot S^2 \\cdot U^T$$\n",
        "\n",
        "Since we need just the matrix U to compute the compressed version of our data, this method will be very convenient. If you are using the collab free plan, the quantity of available ram is not sufficient to compute the SVD of X, therefore computing the SVD of the covariance matrix turns out to be the best solution. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckF8X9KDOQ_9"
      },
      "source": [
        "def svd_k(X, k):\n",
        "  # Compute covariance matrix\n",
        "  C = np.dot(X.T, X)\n",
        "  # SVD decomposition\n",
        "  U, s_sqr, U_T = np.linalg.svd(C, full_matrices=False)\n",
        "  # Limit the number columns of U to k\n",
        "  U_k=U[:,:k]\n",
        "  return U_k\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC6SJH7vzGYa"
      },
      "source": [
        "Let's define the ENCODING_DIM, that will be the size of the compressed version of input data. And compute the compressed version of the training set and the test set.\n",
        "\n",
        "**[TO COMPLETE]**: What happens varying the ENCODING_DIM? test  and discuss the results in a new cell after the following one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIvHTxWpOzCX"
      },
      "source": [
        "ENCODING_DIM = 120\n",
        "\n",
        "U_k=svd_k(x_train, ENCODING_DIM)\n",
        "\n",
        "x_training_pca = np.dot(x_train, U_k)\n",
        "x_test_pca = np.dot(x_test, U_k)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt-gKtEwzvr0"
      },
      "source": [
        "Reconstruct the input and check how much information was lost due to the compression, by computing the mean squared error between the original input and the reconstruction, and by plotting the reconstructed images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GpWcHRkPBJV"
      },
      "source": [
        "x_training_reco= np.dot(x_training_pca, U_k.T)\n",
        "x_test_reco= np.dot(x_test_pca, U_k.T)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CPhgcMZPmtM"
      },
      "source": [
        "accuracy_train = ((x_train - x_training_reco)**2).mean()\n",
        "accuracy_test = ((x_test - x_test_reco)**2).mean()\n",
        "\n",
        "print(\"training mse: %.5f\" % ( accuracy_train))\n",
        "print(\"test mse: %.5f\" % ( accuracy_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuBw_l_Cgo1o"
      },
      "source": [
        "def plot_img(n, input_data, decoded_imgs):\n",
        "  plt.figure(figsize=(20, 4))\n",
        "  for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(input_data[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfqN6d8-37mu"
      },
      "source": [
        "Let's check how well the input can be reconstructed by printing a few of the input images and the corresponding reconstructions. Obviously, all these evaluations have to be done on the test set.\n",
        "\n",
        "The first row of shown images corresponds to input data, while the second one contains the reconstructions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FICZjh2mgz_7"
      },
      "source": [
        "plot_img(10, x_test, x_test_reco)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7crlDsMGrBN"
      },
      "source": [
        "## [TO COMPLETE] Exercise 5.2: Shallow Linear Autoencoder\n",
        "Let's define a model that consists of a single fully-connected neural layer. The hidden layer and the output layer act as the encoder and the decoder, respectively. Differently than the previous homework, instead of using Keras.Sequential(), we define the various part of the model (encoder and decoder) separately and then we create the final model. \n",
        "\n",
        "**[TO COMPLETE]** check the results and compare them versus the results obtained with the SVD. Add a cell  at the end of this section (after the result of the linear autoencoder) where you give an explanation of the relation between the results obtained  by the shallow linear autoencoder and the ones obtained by the SVD decomposition.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfBJJLioaWJN"
      },
      "source": [
        "ENCODING_DIM = 120\n",
        "\n",
        "input_img = tf.keras.layers.Input(shape=(784,))\n",
        "#Define the encoder...\n",
        "encoded = tf.keras.layers.Dense(ENCODING_DIM, activation='linear')(input_img)\n",
        "\n",
        "#...and the decoder...\n",
        "decoded = tf.keras.layers.Dense(784, activation='linear')(encoded)\n",
        "\n",
        "#and finally the autoencoder\n",
        "autoencoder = tf.keras.models.Model(input_img, decoded)\n",
        "\n",
        "# In order to visualize the learned encoding, define a model that computes the \n",
        "# two parts separately.\n",
        "encoder = tf.keras.models.Model(input_img, encoded)\n",
        "encoded_input = tf.keras.layers.Input(shape=(ENCODING_DIM,))\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "decoder = tf.keras.models.Model(encoded_input, decoder_layer(encoded_input))\n",
        "\n",
        "#Finally, let's call the compile method\n",
        "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mse')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_4H-OFzI4tA"
      },
      "source": [
        "Print the model summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gr3B9qoC3zQ"
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz3q7uSsKA2N"
      },
      "source": [
        "Train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szm0L3I03-G9"
      },
      "source": [
        "history = autoencoder.fit(x_train, x_train, epochs=15, batch_size=512, shuffle=True, validation_data=(x_valid, x_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfoaQXZgKJZm"
      },
      "source": [
        "Plot the loss and the accuracy curves on the validation set, and the accuracy on the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15ZjvbTGDB8i"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.plot(history.epoch,history.history['loss'])\n",
        "  plt.plot(history.epoch,history.history['val_loss'])\n",
        "  plt.title('loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vb4ilH-DDyS"
      },
      "source": [
        "plot_loss(history)\n",
        "\n",
        "scores = autoencoder.evaluate(x_test, x_test, verbose=2)\n",
        "print(\"test mse: %.5f\" % (scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgG5Yt9ddmq-"
      },
      "source": [
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)\n",
        "\n",
        "plot_img(10, x_test, decoded_imgs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhhQcerS4Xm0"
      },
      "source": [
        "##[TO COMPLETE] Exercise 5.3: Shallow non-linear autoencoders\n",
        "\n",
        "**[TO COMPLETE]** replicate the code of Exercise 5.1 but in this case, instead of using linear activation functions use  non-linear ones. Choose the most appropriate non-linear function, and motivate your choice. Then discuss the results in relation to those obtained in Exercise 5.1. (Insert your code and  theoretical discussion into  cells immediately below this one.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjzlA8YV4ux5"
      },
      "source": [
        "##[TO COMPLETE] Exercise 5.4: Deep Autoencoder\n",
        "**[TO COMPLETE]**: Define a deep version of the Autoeancoder defined above. The autoencoder has to use at least 5 layers. The model will use $n$ layers for encoding, and n-1 for decoding. The layers sizes of the encoding part decrease at each layer (i.e. 784->128->64, where 64 is the encoding dim). The decoding part layers dimensions progression turns out to be mirrored (i.e 128->784, the resulting overall structure recalls an hourglass).\n",
        "Similarly than what we did above, print the model summary, the loss curves during the training, the achieved loss on the test set, and some input images with the corresponding decoding.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6O7Bq8C4udX"
      },
      "source": [
        "input_img = tf.keras.layers.Input(shape=(784,))\n",
        "#[TO COMPLETE]\n",
        "autoencoder = tf.keras.models.Model()#[TO COMPLETE]\n",
        "\n",
        "autoencoder = tf.keras.models.Model(input_img, decoded)\n",
        "\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XL8uh9MFV03"
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITsWoDrJ4uZy"
      },
      "source": [
        "history = autoencoder.fit(x_train, x_train, epochs= **TO COMPLETE**, batch_size= **TO COMPLETE**, shuffle=True, validation_data=(x_valid, x_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o00moO45Y8F"
      },
      "source": [
        "plot_loss(history)\n",
        "\n",
        "scores = autoencoder.evaluate(x_test, x_test, verbose=2)\n",
        "print(\"test mse: %.5f\" % (scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEmJTRwdFsle"
      },
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "plot_img(10, x_test, decoded_imgs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p55h0PXw5oI4"
      },
      "source": [
        "## [TO COMPLETE] Exercise 5.5: Denoising Autoencoder\n",
        "\n",
        "Let's now use a shallow autoencoder to denoise the input data.\n",
        "Firstly, define a noisy input by adding some noise to our input data. We define a noise factor that can be used to modify the amount of noise to add to the input data. Check how much it influences the denoising capability of the autoencoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEgtUSt1531f"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "x_valid, y_valid = x_train[:10000],y_train[:10000]\n",
        "x_train, y_train = x_train[10000:],y_train[10000:]\n",
        "\n",
        "noise_factor = 0.3\n",
        "\n",
        "x_train_noisy = x_train + noise_factor + np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "x_test_noisy = x_test + noise_factor + np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
        "x_valid_noisy = x_valid + noise_factor + np.random.normal(loc=0.0, scale=1.0, size=x_valid.shape)\n",
        "\n",
        "\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "x_valid_noisy = np.clip(x_valid_noisy, 0., 1.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjpSfN_ZQJge"
      },
      "source": [
        "Plot some noisy inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk_jtv-B6UrS"
      },
      "source": [
        "# here's what the noisy digits look like\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 2))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i + 1)\n",
        "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_i6Z8XfQ5iq"
      },
      "source": [
        "**[TO COMPLETE]** Define a shallow autoencoder able to compute a de-noised version of the input (obtained by unsing a noise_factor >= 0.3). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omRH5b-M6YA_"
      },
      "source": [
        "input_img = tf.keras.layers.Input(shape=(784,))\n",
        "#[TO COMPLETE]\n",
        "\n",
        "autoencoder = tf.keras.models.Model(input_img, decoded)\n",
        "\n",
        "autoencoder.compile()#[TO COMPLETE]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgynPvZ4GUWh"
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRx4JtF_RGQz"
      },
      "source": [
        "**[TO COMPLETE]** Train the model by passing the noisy input and the clean target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMMPGQbO6lBY"
      },
      "source": [
        "history = autoencoder.fit()#[TO COMPLETE]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCw0jn077Wn9"
      },
      "source": [
        "plot_loss(history)\n",
        "\n",
        "scores = autoencoder.evaluate(x_test_noisy, x_test, verbose=2)\n",
        "print(\"test mse: %.5f\" % (scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHOQfAPZRYUY"
      },
      "source": [
        "**[TO COMPLETE]** Check the result by plotting some input images and the corresponding denoised outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUWwHDT3HiGX"
      },
      "source": [
        "decoded_imgs = autoencoder.predict(x_test_noisy)\n",
        "\n",
        "plot_img(10, x_test_noisy, decoded_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lInEGwkch5MW"
      },
      "source": [
        "## Exercise 5.6: Linear Autoencoder for sequences\n",
        "\n",
        "Let's define a linear autoencoder for sequences. In this case, as dataset, we will use the IMDB dataset (already presented in HW4). To have a model that can be trained and tested in a reasonable time (and that works also with the memory limitation that we have in Colab), we will limit the number of training samples and test samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOJLUpNuaEc5"
      },
      "source": [
        "num_words = 100\n",
        "(X_train, _), (X_test, _) = keras.datasets.imdb.load_data(num_words=num_words)\n",
        "\n",
        "X_train=X_train[:10000]\n",
        "\n",
        "(X_valid, X_test) = X_test[:1250], X_test[-1250:]\n",
        "\n",
        "word_index = keras.datasets.imdb.get_word_index()\n",
        "\n",
        "reverse_index = {word_id + 3: word for word, word_id in word_index.items()}\n",
        "reverse_index[0] = \"<pad>\" # padding\n",
        "reverse_index[1] = \"<sos>\" # start of sequence\n",
        "reverse_index[2] = \"<oov>\" # out-of-vocabulary\n",
        "reverse_index[3] = \"<unk>\" # unknown\n",
        "\n",
        "def decode_review(word_ids):\n",
        "    return \" \".join([reverse_index.get(word_id, \"<err>\") for word_id in word_ids])\n",
        "\n",
        "\n",
        "maxlen = 90\n",
        "X_train_trim = keras.preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test_trim = keras.preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen)\n",
        "X_valid_trim = keras.preprocessing.sequence.pad_sequences(X_valid, maxlen=maxlen)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoXke75qeitM"
      },
      "source": [
        "In this case, we want to use as input/target a one-hot representation for each word. To convert the index representation provided by IMDB dataset loader we use the to_categorical method to transform them in the corresponding one hot representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpa0BwSxaXiw"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "X_train_one_hot=to_categorical(X_train_trim)\n",
        "X_test_one_hot=to_categorical(X_test_trim)\n",
        "X_valid_one_hot=to_categorical(X_valid_trim)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gApoz_RFiciZ"
      },
      "source": [
        "Define a linear shallow autoencoder for sequences. The structure will be similar to the model defined in Exercise 5.2, while the used encoding layer is defined by using tf.keras.layers.SimpleRNN. Note that it uses linear activations. The decoding layer exploits [tf.keras.layers.TimeDistributed](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed) that allows using the same dense cell at each time step of the sequence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S69HgNmAicUp"
      },
      "source": [
        "inputs = tf.keras.layers.Input(shape=(maxlen, num_words))\n",
        "encoded = tf.keras.layers.SimpleRNN(50, return_sequences=True, activation='linear')(inputs)\n",
        "\n",
        "decoded = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_words, activation='linear'))(encoded)\n",
        "\n",
        "sequence_autoencoder = tf.keras.models.Model(inputs, decoded)\n",
        "encoder = tf.keras.models.Model(inputs, encoded)\n",
        "\n",
        "sequence_autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=[\"CategoricalAccuracy\"])\n",
        "\n",
        "sequence_autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haFSyKBRjsWW"
      },
      "source": [
        "history = sequence_autoencoder.fit(X_train_one_hot, X_train_one_hot, epochs=50, batch_size=128, shuffle=True, validation_data=(X_valid_one_hot, X_valid_one_hot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXgzgmSA-ZV-"
      },
      "source": [
        "Let's plot the accuracy and the loss trends and check the reconstruction capability of the model by plotting the reconstruction of a test sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N96nqx2nrt9"
      },
      "source": [
        "def plot_categorical_accuracy(history):\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.plot(history.epoch,history.history['categorical_accuracy'])\n",
        "  plt.plot(history.epoch,history.history['val_categorical_accuracy'])\n",
        "  plt.title('accuracy')\n",
        "\n",
        "plot_loss(history)\n",
        "\n",
        "plot_categorical_accuracy(history)\n",
        "\n",
        "scores = sequence_autoencoder.evaluate(X_test_one_hot, X_test_one_hot, verbose=2)\n",
        "print(\"%s: %.2f%%\" % (sequence_autoencoder.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNQmY1kynxe7"
      },
      "source": [
        "decoded_text = sequence_autoencoder.predict(X_test_one_hot)\n",
        "decode_index= np.argmax(decoded_text[500], axis=1)\n",
        "input_text= np.argmax(X_test_one_hot[500], axis=1)\n",
        "\n",
        "print(decode_review(input_text))\n",
        "print(decode_review(decode_index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW5BipraiQiE"
      },
      "source": [
        "##[TO COMPLETE] Exercise 5.7: Non-Linear Autoencoder for sequences\n",
        "**[TO COMPLETE]**: Replicate the code of the above exercise, but instead of using a simpleRNN with linear activation do the same  using  non-linear activation functions and using an LSTM layer. Choose the most appropriate non-linear function, and motivate your choice. Then discuss the results in relation to those obtained by the linear autoencoder for sequences.\n",
        "\n",
        "Hint: using a non-linear function also in the dense layer after the RNN/LSTM one will help to obtain better results. The choice of this function should be based on the type of output data."
      ]
    }
  ]
}